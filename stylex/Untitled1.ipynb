{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7e32a8b-17ed-40ca-8fe0-78735f1140c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 23:46:19.426555: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from segmentation_model import SegmentationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d5d827a-0a1c-4103-85ec-3a85523f7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_path = \"mnist.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5e1c18a-a2cc-41e0-aedc-d8437cf4fcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/thesis/thesis_experiment_1/stylex\n"
     ]
    }
   ],
   "source": [
    "model = SegmentationModel(classifier_path, cuda_rank= 1, output_size = 256 ,\n",
    "                                        image_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "830c584e-4012-43ca-942e-ce22bfb5cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from gray2color import gray2color\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f406c1c-cc02-4d3d-a4c2-a317cec26d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_pallet = np.array([[[0, 0, 0],\n",
    "                      [204, 0, 0],\n",
    "                      [76, 153, 0],\n",
    "                      [204, 204, 0],\n",
    "                      [51, 51, 255],\n",
    "                      [204, 0, 204],\n",
    "                      [0, 255, 255],\n",
    "                      [255, 204, 204],\n",
    "                      [102, 51, 0],\n",
    "                      [255, 0, 0],\n",
    "                      [102, 204, 0],\n",
    "                      [255, 255, 0],\n",
    "                      [0, 0, 153],\n",
    "                      [0, 0, 204],\n",
    "                      [255, 51, 153],\n",
    "                      [0, 204, 204],\n",
    "                      [0, 51, 0],\n",
    "                      [255, 153, 51],\n",
    "                      [0, 204, 0]]], np.uint8) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bafc2c2-98f2-4059-b74e-bd4dfe2509fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ae4e26-8ef0-4cde-9fbf-44012ef771f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.cuda(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f54e3db-2e4c-4911-a752-ed9c63c07710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir(\"../data/Kaggle_FFHQ_Resized_256px/flickrfaceshq-dataset-nvidia-resized-256px/resized_sub/00001.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d47969f-f5c3-4342-97e0-f4984ab40b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"../data/Kaggle_FFHQ_Resized_256px/flickrfaceshq-dataset-nvidia-resized-256px/resized_sub/00002.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "325f27ae-a8fd-4d89-9af1-30dafc06247d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0078, 0.0039, 0.0078,  ..., 0.0314, 0.0314, 0.0314],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0314, 0.0314, 0.0314],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0353, 0.0353, 0.0353],\n",
      "         ...,\n",
      "         [0.4314, 0.4353, 0.4275,  ..., 0.8157, 0.7882, 0.7451],\n",
      "         [0.4235, 0.4235, 0.4275,  ..., 0.7922, 0.8039, 0.8275],\n",
      "         [0.4275, 0.4235, 0.4196,  ..., 0.7804, 0.7961, 0.8314]],\n",
      "\n",
      "        [[0.0078, 0.0039, 0.0078,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         ...,\n",
      "         [0.0980, 0.1020, 0.1020,  ..., 0.5098, 0.4824, 0.4392],\n",
      "         [0.1020, 0.1020, 0.1020,  ..., 0.4863, 0.4980, 0.5216],\n",
      "         [0.1059, 0.1020, 0.0941,  ..., 0.4745, 0.4902, 0.5255]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "         ...,\n",
      "         [0.0196, 0.0235, 0.0314,  ..., 0.3294, 0.3020, 0.2588],\n",
      "         [0.0196, 0.0196, 0.0314,  ..., 0.2980, 0.3098, 0.3333],\n",
      "         [0.0235, 0.0196, 0.0235,  ..., 0.2863, 0.3020, 0.3373]]])\n"
     ]
    }
   ],
   "source": [
    "convert_tensor = transforms.ToTensor()\n",
    "tensor_img = convert_tensor(img)\n",
    "print(tensor_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a675652-f476-4b9e-9abd-85c85bb88257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type <class 'numpy.ndarray'>\n",
      "dtype float16\n",
      "mask_pred shape: <class 'PIL.Image.Image'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63266/2952436202.py:21: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  mask_pred=mask_pred.resize((256,256), Image.NEAREST)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAAAVElEQVR4nO3BAQEAAACAkP6v7ggKAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGAEPAAFN9soGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = tensor_img\n",
    "inputs = inputs.cuda(1)\n",
    "outputs = model.get_segmentation_logits(inputs.unsqueeze(0))\n",
    "# imname = os.path.basename(dataset.images[i])\n",
    "# fname,ext = os.path.splitext(imname)\n",
    "# print(fname)\n",
    "t_npy = outputs.detach().cpu().numpy()\n",
    "t_npy = t_npy.astype(np.float16)\n",
    "        # print(\"Numpy:\",type(t_npy))\n",
    "        # savez_compressed('data.npz', data)\n",
    "# savez_compressed('./flickrfaceshq-dataset-nvidia-resized-256px/logits/'+fname+'.npz', t_npy)\n",
    "print(\"type\",type(t_npy))\n",
    "print(\"dtype\",t_npy.dtype)\n",
    "        # print(\"logits\",outputs)\n",
    "        # print(\"Tensor on cuda\",outputs.is_cuda)\n",
    "_, pred = torch.max(outputs, 1)\n",
    "pred = pred.data.cpu().numpy().squeeze().astype(np.uint8)\n",
    "        # print(type(pred))\n",
    "mask_pred = Image.fromarray(pred)\n",
    "print(\"mask_pred shape:\", type(mask_pred))\n",
    "mask_pred=mask_pred.resize((256,256), Image.NEAREST)\n",
    "display(mask_pred)\n",
    "pix = np.array(mask_pred)\n",
    "        # print(type(pix))\n",
    "        # mask = cv2.imread('../gray.png', 0)\n",
    "rgb = gray2color(pix, use_pallet=None, custom_pallet=c_pallet)\n",
    "        # print(type(rgb))\n",
    "im = Image.fromarray(rgb)\n",
    "im.save('../data/Kaggle_FFHQ_Resized_256px/flickrfaceshq-dataset-nvidia-resized-256px/seg/'+ \"test_seg\" + '.png')\n",
    "        # print(dataset.images[i])\n",
    "            # mask_pred.save(dataset.images[i].replace(imname,'parsings/'+imname[:-4]+'.png'))\n",
    "        # mask_pred.save('./flickrfaceshq-dataset-nvidia-resized-256px/seg/'+ str(i) + '.png')\n",
    "        # except FileNotFoundError:\n",
    "        #     os.makedirs(os.path.join(os.path.dirname(dataset.images[i]),'parsings'))\n",
    "        #     mask_pred.save(dataset.images[i].replace(imname,'parsings/'+imname[:-4]+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b359fd41-6d3e-47cf-bf28-f06db45e612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1be16f9f-f81f-4afa-acf8-16cf584abb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddae6f29-4663-41a8-b509-2e3fb9234146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1339359232, 47850782720)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.mem_get_info(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4acd8ae8-7788-4e51-a864-c34da7092d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47850782720\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(1).total_memory\n",
    "print(t)\n",
    "r = torch.cuda.memory_reserved(1)\n",
    "print(r)\n",
    "a = torch.cuda.memory_allocated(1)\n",
    "print(a)\n",
    "f = r-a  # free inside reserved\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b8ab15-a695-4e2a-812a-3f60e2bdd130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
